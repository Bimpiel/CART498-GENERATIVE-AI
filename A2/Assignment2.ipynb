{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEwaZx4KGzHVM7O3k6NgPq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bimpiel/CART498-GENERATIVE-AI/blob/main/A2/Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hvM0P0mOEIvI"
      },
      "outputs": [],
      "source": [
        "# prompt: save the output to a file called p+7\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, LogitsProcessorList, TopKLogitsWarper\n",
        "import torch\n",
        "import random\n",
        "# Import necessary libraries\n",
        "\n",
        "# Initialize the GPT-2 tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
        "\n",
        "# List of sentences to complete\n",
        "prompts = [\n",
        "    \"One must have a mind of winter\",\n",
        "    \"To regard the frost and the boughs\",\n",
        "    \"Of the pine-trees crusted with snow;\",\n",
        "    \"And have been cold a long time\",\n",
        "    \"To behold the junipers shagged with ice,\",\n",
        "    \"The spruces rough in the distant glitter\",\n",
        "    \"Of the January sun; and not to think\",\n",
        "    \"Of any misery in the sound of the wind,\",\n",
        "    \"In the sound of a few leaves,\",\n",
        "    \"Which is the sound of the land\",\n",
        "    \"Full of the same wind\",\n",
        "    \"That is blowing in the same bare place\",\n",
        "    \"For the listener, who listens in the snow,\",\n",
        "    \"And, nothing himself, beholds\",\n",
        "    \"Nothing that is not there and the nothing that is.\"\n",
        "]\n",
        "\n",
        "# Function to generate the next token and replace the last word of the sentence\n",
        "def complete_sentence(prompt):\n",
        "    # Remove the last word of the prompt\n",
        "    prompt_without_last_word = ' '.join(prompt.split()[:-1])\n",
        "\n",
        "    # Tokenize the prompt without the last word and convert it to input IDs\n",
        "    input_ids = tokenizer(prompt_without_last_word, return_tensors=\"pt\").input_ids\n",
        "\n",
        "    # Generate the model's output logits for the next token\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids)\n",
        "        logits = outputs.logits[:, -1, :]  # Get logits for the last token\n",
        "\n",
        "    # Apply a Top-K logits processor to focus on the most probable continuations\n",
        "    logits_processor = LogitsProcessorList([TopKLogitsWarper(top_k=50)])\n",
        "    processed_logits = logits_processor(input_ids, logits)\n",
        "\n",
        "    # Convert logits to probabilities using softmax\n",
        "    probabilities = torch.softmax(processed_logits, dim=-1).squeeze()\n",
        "\n",
        "    # Get the top 7 most probable tokens and their probabilities\n",
        "    top_k = 7\n",
        "    top_probs, top_indices = torch.topk(probabilities, top_k)\n",
        "\n",
        "    # Decode the tokens, remove the 'Ġ' prefix, and pair them with their probabilities\n",
        "    continuations = [token.replace('Ġ', '') for token in tokenizer.convert_ids_to_tokens(top_indices.tolist())]\n",
        "    results = list(zip(continuations, top_probs.tolist()))\n",
        "\n",
        "    # Randomly choose one of the top 7 words\n",
        "    chosen_word = random.choice(continuations)\n",
        "\n",
        "    # Replace the last word of the original prompt with the chosen word\n",
        "    completed_sentence = f\"{prompt_without_last_word} {chosen_word}\"\n",
        "\n",
        "    return results, completed_sentence\n",
        "\n",
        "# Loop over each prompt and generate the results\n",
        "with open(\"p+7.txt\", \"w\") as f:\n",
        "    for prompt in prompts:\n",
        "        results, completed_sentence = complete_sentence(prompt)\n",
        "        print(completed_sentence, file=f)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Version 2: Change X for different outcome"
      ],
      "metadata": {
        "id": "dUKtmX3_LgL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: A second version of the text processed with P+x. Choose an x value that produces the funniest, wittiest, or most absurd version of the original text. Save this as a .txt file, and include the x value in the filename\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, LogitsProcessorList, TopKLogitsWarper\n",
        "import torch\n",
        "import random\n",
        "\n",
        "# Initialize the GPT-2 tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
        "\n",
        "# List of sentences to complete\n",
        "prompts = [\n",
        "    \"One must have a mind of winter\",\n",
        "    \"To regard the frost and the boughs\",\n",
        "    \"Of the pine-trees crusted with snow;\",\n",
        "    \"And have been cold a long time\",\n",
        "    \"To behold the junipers shagged with ice,\",\n",
        "    \"The spruces rough in the distant glitter\",\n",
        "    \"Of the January sun; and not to think\",\n",
        "    \"Of any misery in the sound of the wind,\",\n",
        "    \"In the sound of a few leaves,\",\n",
        "    \"Which is the sound of the land\",\n",
        "    \"Full of the same wind\",\n",
        "    \"That is blowing in the same bare place\",\n",
        "    \"For the listener, who listens in the snow,\",\n",
        "    \"And, nothing himself, beholds\",\n",
        "    \"Nothing that is not there and the nothing that is.\"\n",
        "]\n",
        "\n",
        "# Function to generate the next token and replace the last word of the sentence\n",
        "def complete_sentence(prompt, x_value): # Added x_value as parameter\n",
        "    # Remove the last word of the prompt\n",
        "    prompt_without_last_word = ' '.join(prompt.split()[:-1])\n",
        "\n",
        "    # Tokenize the prompt without the last word and convert it to input IDs\n",
        "    input_ids = tokenizer(prompt_without_last_word, return_tensors=\"pt\").input_ids\n",
        "\n",
        "    # Generate the model's output logits for the next token\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids)\n",
        "        logits = outputs.logits[:, -1, :]  # Get logits for the last token\n",
        "\n",
        "    # Apply a Top-K logits processor to focus on the most probable continuations\n",
        "    logits_processor = LogitsProcessorList([TopKLogitsWarper(top_k=x_value)]) # Use x_value for top_k\n",
        "    processed_logits = logits_processor(input_ids, logits)\n",
        "\n",
        "    # Convert logits to probabilities using softmax\n",
        "    probabilities = torch.softmax(processed_logits, dim=-1).squeeze()\n",
        "\n",
        "    # Get the top 7 most probable tokens and their probabilities\n",
        "    top_k = 7 # Keep top_k as 7\n",
        "    top_probs, top_indices = torch.topk(probabilities, top_k)\n",
        "\n",
        "    # Decode the tokens, remove the 'Ġ' prefix, and pair them with their probabilities\n",
        "    continuations = [token.replace('Ġ', '') for token in tokenizer.convert_ids_to_tokens(top_indices.tolist())]\n",
        "    results = list(zip(continuations, top_probs.tolist()))\n",
        "\n",
        "    # Randomly choose one of the top 7 words\n",
        "    chosen_word = random.choice(continuations)\n",
        "\n",
        "    # Replace the last word of the original prompt with the chosen word\n",
        "    completed_sentence = f\"{prompt_without_last_word} {chosen_word}\"\n",
        "\n",
        "    return results, completed_sentence\n",
        "\n",
        "# Choose an x value\n",
        "x = random.randrange(8,30)\n",
        "\n",
        "# Loop over each prompt and generate the results\n",
        "filename = f\"p+{x}.txt\"\n",
        "with open(filename, \"w\") as f:\n",
        "    for prompt in prompts:\n",
        "        results, completed_sentence = complete_sentence(prompt, x) # Pass x_value to the function\n",
        "        print(completed_sentence, file=f)"
      ],
      "metadata": {
        "id": "dvCNDISFLj82"
      },
      "execution_count": 3,
      "outputs": []
    }
  ]
}